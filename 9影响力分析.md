//张盆希202313093039
install.packages("tm")
install.packages("syuzhet")
library(tm)
library(syuzhet)
# 创建一个假设的社交媒体帖子数据集
social_media_data <- data.frame(
  author = c("Alice", "Bob", "Charlie", "David", "Eve"),
  post = c("I love this product!", "This is the worst thing ever.", 
           "Great service, would recommend!", "Horrible experience.", 
           "Absolutely fantastic!")
)

# 文本挖掘：创建语料库
corpus <- Corpus(VectorSource(social_media_data$post))

# 文本预处理
corpus_clean <- tm_map(corpus, content_transformer(tolower))
corpus_clean <- tm_map(corpus_clean, removePunctuation)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords("en"))
corpus_clean <- tm_map(corpus_clean, stripWhitespace)

# 计算词频
tdm <- TermDocumentMatrix(corpus_clean)
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)

# 情感分析
sentiment_scores <- sapply(social_media_data$post, get_nrc_sentiment)

# 将情感分析结果添加到数据集中
social_media_data$sentiment <- sentiment_scores

# 输出结果
print(social_media_data)
